{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.5.2"
    },
    "colab": {
      "name": "hw3.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9lAsyeOwFnoX"
      },
      "source": [
        "# CSCE 623 Homework Assignment 3\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "46d-KBtJJxN1"
      },
      "source": [
        "### Student Name:  <font color=\"blue\">Timothy Kokotajlo</font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yna07rL4Jz43"
      },
      "source": [
        "### Date: <font color=\"blue\">5/4/2021</font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P685WkBlKB2x"
      },
      "source": [
        "## Disclosures\n",
        "\n",
        "*   None"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zXzR22oMKEtf"
      },
      "source": [
        "## Overview\n",
        "\n",
        "In this homework assignment, you will explore various methods of cross-validation. \n",
        "\n",
        "We will introduce you to a generated dataset that represents a polynomial function with gaussian noise. You will attempt to fit various models of increasing flexibility (polynomial order) to the data. You will analyze and evaluate each models using cross-validation to (1) determine the model that best fits the data, and (2) predict the performance of your model on new data.\n",
        "\n",
        "You will then compare the model you developed using machine learning techniques to the model indicated by statistical analysis.\n",
        "\n",
        "This assignment includes both written and programming components."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qbbSOVyq7lYk"
      },
      "source": [
        "### Written Components\n",
        "Full effort answers to written components should include not only the answer to the question, but they should also include supporting information. You should provide justification or supporting information even if the question only asks for a single number or short answer."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a-5OaiNO7m6F"
      },
      "source": [
        "### Programming Components\n",
        "Use Python to perform any manipulations you make to provided datasets, all calculations and mathematical transformations, and to generate graphs, figures, or other support to explain how you arrived at your written answers."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a0Zjdxie-jWf"
      },
      "source": [
        "### Helpful Tips\n",
        "\n",
        "You might find these Python packages/imports helpful\n",
        "\n",
        "``` python\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import math\n",
        "import seaborn as sns\n",
        "\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.model_selection import ShuffleSplit\n",
        "from sklearn.model_selection import LeaveOneOut\n",
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "from IPython.display import Markdown as md\n",
        "\n",
        "from sklearn.linear_model import LinearRegression\n",
        "\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "%matplotlib inline\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kS60EAw9MiU2"
      },
      "source": [
        "## Cross-fold Validation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A5yhrcvjN0AD"
      },
      "source": [
        "### STEP 0: installs & configuration"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pFdGmA3GN3_q"
      },
      "source": [
        "Install any packages you need for your notebook. If using the Google Colab environment, you will not need to install any additional packages."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AqoMuH_YOJ3e"
      },
      "source": [
        "\"\"\"\n",
        "CSCE 623 HW3. Cross-fold Validation\n",
        "\"\"\"\n",
        "DEBUG = True\n",
        "\n",
        "# install packages, set configuration, as needed\n"
      ],
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1HI9buTTOPHH"
      },
      "source": [
        "Import any packages you need for your notebook"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2yVNfQdnY7BW"
      },
      "source": [
        "# import pacakages for your notebook\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import math\n",
        "import seaborn as sns\n",
        " \n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.model_selection import ShuffleSplit\n",
        "from sklearn.model_selection import LeaveOneOut\n",
        "from sklearn.model_selection import cross_val_score\n",
        " \n",
        "from IPython.display import Markdown as md\n",
        " \n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.linear_model import LogisticRegression\n",
        " \n",
        "from sklearn.metrics import mean_squared_error\n",
        " \n",
        "%matplotlib inline\n",
        "\n",
        "%matplotlib inline"
      ],
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4pD5Jejhp70q",
        "tags": [
          "remove_cell"
        ]
      },
      "source": [
        "# instructor provided code\n",
        "plot_x_min = -2.\n",
        "plot_x_max = 2.\n",
        "\n",
        "def generate_data(seed = 1, quantity = 200, test_data = False):\n",
        "    np.random.seed(seed)\n",
        "    x = np.random.uniform(low=plot_x_min,high=plot_x_max,size=quantity)\n",
        "    order = np.random.randint(3, 4)\n",
        "    betas = np.random.uniform(-2, 2, order)\n",
        "\n",
        "    y = sum((beta * x ** (idx+1) for idx, beta in enumerate(betas)))\n",
        "\n",
        "    beta0 = np.random.uniform(np.min(y), np.max(y))\n",
        "\n",
        "    noise = np.random.normal(size=quantity, scale = (np.max(y) - np.min(y)) / 8)\n",
        "    if test_data: # get new sample if we're generating test data\n",
        "        noise = np.random.normal(size=quantity, scale = (np.max(y) - np.min(y)) / 8)\n",
        "\n",
        "    y += noise + beta0\n",
        "\n",
        "    df = pd.DataFrame({'x': x, 'y': y})\n",
        "\n",
        "    globals()['global_betas'] = betas\n",
        "    globals()['global_beta0'] = beta0\n",
        "\n",
        "    return(df) "
      ],
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xRPFmS9PJVGI"
      },
      "source": [
        "### STEP A: provided functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-feg5ea9I_sE"
      },
      "source": [
        "# instructor provided functions\n",
        "\"\"\"\n",
        "returns a LaTeX style string representing a function defined by beta0 and betas\n",
        "\"\"\"\n",
        "def create_model_string(beta0, betas):\n",
        "    model_function = f'$f(x) = {beta0:.2f}'\n",
        "    for idx, beta in enumerate(betas):\n",
        "        model_function += f' + {beta:.2f}x^{idx+1}'\n",
        "    model_function += '$'\n",
        "    return model_function\n",
        "\n",
        "\"\"\"\n",
        "adds a plot of a function to the current plot\n",
        "\"\"\"\n",
        "def plot_function(x_min, x_max, beta0, betas, resolution = .1, style = None, label = ''):\n",
        "    plot_x = np.arange(x_min - .2 * abs(x_min), x_max + .2 * abs(x_max), resolution)\n",
        "    plot_y = sum((beta * plot_x ** (idx+1) for idx, beta in enumerate(betas))) + beta0\n",
        "    if style:\n",
        "        plt.plot(plot_x, plot_y, style, label=label)\n",
        "    else:\n",
        "        plt.plot(plot_x, plot_y, label=label)\n",
        "\n"
      ],
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vnE14vxA2VvU"
      },
      "source": [
        "### STEP 1: scikit-learn Functions\n",
        "\n",
        "Review the scikit-learn documentation for the following functions and answer the questions that follow:\n",
        "\n",
        "- [User Guide for cross validation iterators](https://scikit-learn.org/stable/modules/cross_validation.html#cross-validation-iterators)\n",
        "  - Identically Distributed Data\n",
        "    - [KFold](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.KFold.html#sklearn.model_selection.KFold)\n",
        "    - [RepeatedKFold](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.RepeatedKFold.html#sklearn.model_selection.RepeatedKFold)\n",
        "    - [LeaveOneOut](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.LeaveOneOut.html)\n",
        "    - [LeavePOut](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.LeavePOut.html#sklearn.model_selection.LeavePOut)\n",
        "    - [ShuffleSplit](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.ShuffleSplit.html#sklearn.model_selection.ShuffleSplit)\n",
        "  - Stratification with Class Data\n",
        "    - [StratifiedKFold](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.StratifiedKFold.html#sklearn.model_selection.StratifiedKFold)\n",
        "    - [RepeatedStratifiedKFold](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.RepeatedStratifiedKFold.html#sklearn.model_selection.RepeatedStratifiedKFold)\n",
        "    - [StratifiedShuffleSplit](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.StratifiedShuffleSplit.html#sklearn.model_selection.StratifiedShuffleSplit)\n",
        "  - Grouped Data\n",
        "    - [GroupKFold](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GroupKFold.html#sklearn.model_selection.GroupKFold)\n",
        "    - [LeaveOneGroupOut](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GroupKFold.html#sklearn.model_selection.GroupKFold)\n",
        "    - [LeavePGroupsOut](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.LeavePGroupsOut.html#sklearn.model_selection.LeavePGroupsOut)\n",
        "    - [GroupShuffleSplit](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GroupShuffleSplit.html#sklearn.model_selection.GroupShuffleSplit)\n",
        "\n",
        "\n",
        "\n",
        "### Discussion\n",
        "\n",
        "- Using one of the functions listed above, what is the most straight-forward way to implement \"The Validation Set\" approach discussed in _ISLR_, 5.1.1 on regression data? What function would you use? What argument values would you use?\n",
        "\n",
        "  <font color=green class=\"student_answer\">Student Answer</font>\n",
        "\n",
        "- What function and arguments would you use to implement LOOCV as discussed in _ISLR_ 5.1.2?\n",
        "\n",
        "  <font color=green class=\"student_answer\">Student Answer</font>\n",
        "\n",
        "- How would you implement k-fold Cross-Validation as discussedd in _ISLR_ 5.1.3? Assuming $k = 10$, what argument values would you use?\n",
        "\n",
        "  <font color=green class=\"student_answer\">Student Answer</font>\n",
        "\n",
        "- If the problem is a classification problem how would you ensure that each _k-fold_ had a balance of classes represented in the data? What function and argument values would you use assuming $k = 10$?\n",
        "\n",
        "  <font color=green class=\"student_answer\">Student Answer</font>\n",
        "\n",
        "- Suppose you wanted to train multiple models using k-fold cross-validation each with $k=10$ and compare their performance. What arguments would you use?\n",
        "\n",
        "  <font color=green class=\"student_answer\">Student Answer</font>\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4Vi2UU9HDUVR"
      },
      "source": [
        "STEP_1_COMPLETE = False"
      ],
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z4Lwf_jiXqXK"
      },
      "source": [
        "### Data Analysis\n",
        "\n",
        "In steps 1-2, you'll load and conduct an analysis of a generated dataset."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EwKDAUtjFnof"
      },
      "source": [
        "#### STEP 2: load dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G7c6P84MOuJB"
      },
      "source": [
        "For this assignment, you will use a generated dataset. You have been provided a function that will generate a dataset. You need only provide a random seed value to generate a unique dataset.\n",
        "\n",
        "You'll initialize a dataset unique to yourself by choosing a random seed value. You can initialize the seed with the last 4 digits of your phone number, your street address, or some other number.\n",
        "\n",
        "You'll then generate the dataset and store it in a Dataframe named df:\n",
        "```\n",
        "df = generate_data(seed)\n",
        "```\n",
        "\n",
        "IMPORTANT: After choosing a seed value, you will not want to change this value, as changing the seed will result in your dataset changing. This will invalidate any analysis that you've completed. \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "_tQNDIVeFnog"
      },
      "source": [
        "#STEP 2\n",
        "\n",
        "#STUDENT CODE - insert code to load a generated dataset using pandas\n",
        "# store your data in a dataframe called 'df'\n",
        "#--------------------------------------------- \n",
        "\n",
        "df = generate_data(13371337)\n",
        "\n",
        "#---------------------------------------------    \n",
        "\n",
        "STEP_2_COMPLETE = False"
      ],
      "execution_count": 74,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TawtbcrZBEuH"
      },
      "source": [
        "#### STEP 3: plot and analyze data\n",
        "\n",
        "Using a similar approach that you employed in homework assignments 1 and 2, plot and analyze the dataset.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pFCTBu8kCH38"
      },
      "source": [
        "#STEP 3\n",
        "\n",
        "#STUDENT CODE - insert code to plot and use pandas analysis tools on the dataset\n",
        "#---------------------------------------------\n",
        "#graph it\n",
        "\n",
        "#statistics \n",
        "\n",
        "#pairplot\n",
        "\n",
        "#histogram\n",
        "#--------------------------------------------- "
      ],
      "execution_count": 75,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3rDHXs2IC2Bx"
      },
      "source": [
        "Discuss the dataset, being sure to answer such questions as:\n",
        "- How many observations are in the dataset?\n",
        "- How many features?\n",
        "- What is the nature of the target (regression or classification)?\n",
        "- What kind of relationship will best fit the data? Linear? Polynomial? If polynomial, what order?\n",
        "  \n",
        "  <font color=green class=\"student_answer\">Student Discussion</font>\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YxcxNljkDYRn"
      },
      "source": [
        "#200 observations\n",
        "#2 features\n",
        "#it looks like a regression problem\n",
        "#looks like a polynomial relationship, probably second order. \n",
        "\n",
        "STEP_3_COMPLETE = True"
      ],
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GEjQYr2oB4pj"
      },
      "source": [
        "#### STEP 4: initial hypothesis\n",
        "\n",
        "Develop an initial hypothesis about the best model that will fit the data and overlay it on a scatterplot of the dataset. Be sure to use a model informed by your analysis above. I've provided an example below. While my example is quadratic, your model might not necessarily be quadratic. Feel free to use either of the functions provided in SETUP A above.\n",
        "\n",
        "![initial guess](https://raw.githubusercontent.com/afit-csce623-master/template-hw3/main/images/plot_guess_overlay2.png)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9zBQSfynCYsN"
      },
      "source": [
        "#STEP 4\n",
        "\n",
        "#STUDENT CODE - insert code to overlay your initial hypothesis on a scatter plot of the dataset\n",
        "#---------------------------------------------\n",
        "\n",
        "#---------------------------------------------\n",
        "\n",
        "STEP_4_COMPLETE = False"
      ],
      "execution_count": 77,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "80j7ZKyoDs_c"
      },
      "source": [
        "### Feature Engineering\n",
        "\n",
        "In this section, you'll implement code to create a new dataframe with engineered features."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RHKjj6oeEG4c"
      },
      "source": [
        "#### STEP 5: feature engineering\n",
        "\n",
        "`df` contains a feature and a target. You will create a function that will generate a new feature dataframe that will generate a new dataframe with $p$ columns, where column $p$ will contain the the values of $x^p$.\n",
        "\n",
        "Your function will have the signature `poly_df(x, p)` where `x` is a series of feature values and `p` is the highest order polynomial desired. The function will return a dataframe where the first column contains the original feature values ($x^1$), the second column contains the quadratic values ($x^2$), the third column has cubic values ($x^3$), and so forth. Provide header values of `x^1`, `x^2`, `x^3`, etc.\n",
        "\n",
        "This is an example of a displayed dataframe returned after calling `poly_df(df.x, 6)` (specific values will differ).\n",
        "\n",
        "![polynomial dataframe](https://raw.githubusercontent.com/afit-csce623-master/template-hw3/main/images/poly_dataframe.png)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XOGdRpJ3IEWM"
      },
      "source": [
        "#STEP 5\n",
        "\n",
        "#STUDENT CODE - insert code to implement poly_df\n",
        "#---------------------------------------------\n",
        "\n",
        "def poly_df(x, p):\n",
        "  #create new df, set equal to x\n",
        "  headers = []\n",
        "  #for a in range(p):\n",
        "    #headers.append('x'+str(a))\n",
        "\n",
        "  new_df = pd.DataFrame(columns=headers)\n",
        "  for item in range(p):\n",
        "    headers.append('x'+str(item+1))\n",
        "    new_df[headers[item]] = x**(item+1)\n",
        "  return new_df \n",
        "#display(df.x)\n",
        "#display(poly_df(df.x ,6))\n",
        "#---------------------------------------------\n",
        "\n",
        "STEP_5_COMPLETE = False"
      ],
      "execution_count": 78,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "81Ntq_t1fi2C"
      },
      "source": [
        "### 3 Ways to Cross Validate\n",
        "\n",
        "In the following section, we will explore the three methods of cross-validation discussed in the _ISLR_ text:\n",
        "\n",
        "- Validation Set\n",
        "- Leave One Out\n",
        "- K-Fold\n",
        "\n",
        "For each method, we'll execute three steps:\n",
        "\n",
        "1. Write a function to calculate the root mean squared error using the intended cross-validation method.\n",
        "2. Generate a DataFrame of root mean squared error values using the cross-validation technique for models of increasing flexibility. Specifically, you'll evaluate 8 models, polynomial models, ordered 1 through 8.\n",
        "3. Plot the spaghetti chart of the root mean squared error values\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rak97xTA3pah"
      },
      "source": [
        "#### SETUP B: constants for cv\n",
        "\n",
        "Here are constants available for your use in STEPS 6-14"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fvAFdvhD1xI-"
      },
      "source": [
        "# instructor provided constants:\n",
        "\n",
        "# feel free to use throughout the following STEPs\n",
        "\n",
        "TRIALS = 10\n",
        "MAX_ORDER = 8\n",
        "COLUMNS = ['Trial 1', 'Trial 2', 'Trial 3', 'Trial 4', 'Trial 5', 'Trial 6', 'Trial 7', 'Trial 8', 'Trial 9', 'Trial 10']\n",
        "INDICES = ['1st', '2nd', '3rd', '4th', '5th', '6th', '7th', '8th']\n"
      ],
      "execution_count": 79,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PGvmAaG3DiE-"
      },
      "source": [
        "#### Validation Set Approach\n",
        "\n",
        "In this section, you will evaluate models of increasing flexibility (up to 8th order polynomial) fit to the generated data."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mJ8SnNJIKycu"
      },
      "source": [
        "##### STEP 6: validation set rmse\n",
        "\n",
        "In this step, you'll create `val_set_mse(X, y, random_state)` which returns the root mean squared error of a model fit to a training set and evaluated on a validation set.\n",
        "\n",
        "- `X` is a DataFrame of feature inputs\n",
        "- `y` is a Series of targets\n",
        "- return a scalar value representing the root mean squared error\n",
        "\n",
        "Hints:\n",
        "- The instructor's solution to this function uses only 4 lines of code--no Python tricks. If you're using more than 6-8 lines of code, you may not be doing something right\n",
        "- You'll use the scikit-learn [cross_val_score](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.cross_val_score.html) function to calculate the root mean squared error. The use of this function may be a bit non-standard for the typical programmer. While the `X` and `y` arguments are pretty straight-forward, three arguments in particular may be confounding:\n",
        "  - `estimator` is the model type. Usually, you'll set this in advance and then pass in a reference to the model. For example, if you wanted to use a [LogisticRegression](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html) model using the `liblinear` solver, you might do the following:\n",
        "    ```\n",
        "    model = LogisticRegression(solver='liblinear')\n",
        "    ```\n",
        "    and then you would pass in `model` as the `cross_val_score` estimator. There is an additional example on the bottom of page 73 in _HOML_ that uses a DecisionTreeRegressor defined near the top of the page.\n",
        "  - `cv` is an integer or a cross-validation generator. Unless you're doing k-fold validation, you'll need to provide a generator. The generators are those iterators you reviewed in STEP 1. For example, if you wanted to train and validate on possible training/validaton sets when you remove 12 samples from the dataset, you might do the following:\n",
        "    ```\n",
        "    lpo = LeavePOut(p=12)\n",
        "    ```\n",
        "    and pass in `lpo` as the `cv` generator\n",
        "  - `scoring` is a scoring methodology. You can create your own scoring function, but often, using a [predefined scoring method](https://scikit-learn.org/stable/modules/model_evaluation.html#scoring-parameter) is suitable. Note that all scoring methods follow the \"greater is better\" principal. Therefore, many of the regression scores are negated. To report the actual score of a negated value, you'll need to take the absolute value or negation of the score. See also pages 73-74 of _HOML_. Note that _HOML_ collects the root mean squared error from the `cross_val_score` method and then take the square root of the negation to calculate RMSE. Observe that the negated RMSE metric is available directly as a scoring methodology, so the square root step isn't be necessary.\n",
        "- An algorithm for completing this task:\n",
        "  - Identify the correct cross validation iterator for this problem, and create the generator with all appropriate parameters, assigning it to a variable. NOTES (these are things to consider after you have basic functionality):\n",
        "    - For the sake of repeatability, you'll want to set the `random_state` value. However, if you set `random_state` to a number, you'll get the exact same train/validation partition every time you call the function. Instead, use a seeded [RandomState](https://numpy.org/doc/1.16/reference/generated/numpy.random.RandomState.html).\n",
        "    - Be sure that you're splitting the dataset in half for the train and validation sets\n",
        "  - Identify the correct model type for this problem, and create the model with all appropriate parameters, assigning it to a variable\n",
        "  - Call cross_val_score, selecting the appropriate scoring metric and assigning the result to a variable\n",
        "  - Correct for negation and return the score"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S7wrEbTiYq9K",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "81a9bc2c-c542-4eaa-fd16-fcb6a3ea788c"
      },
      "source": [
        "#STEP 6\n",
        "\n",
        "#STUDENT CODE - insert code to implement val_set_mse(X, y, random_state)\n",
        "#---------------------------------------------\n",
        "\n",
        "\n",
        "#lpo = scikitlearn.LeavePOut(p=12)\n",
        "#from sklearn.model_selection import KFold\n",
        "#from sklearn.model_selection import ShuffleSplit\n",
        "#from sklearn.model_selection import LeaveOneOut\n",
        "#from sklearn.model_selection import cross_val_score\n",
        "\n",
        "#lpo = KFold(12, random_state=1337)\n",
        "#lpo = ShuffleSplit(random_state=1337)\n",
        "#lpo = LeaveOneOut(random_state=1337)\n",
        "#display(df.y)\n",
        "model = LinearRegression()#.fit(df.x, df.y)\n",
        "random_state = np.random.RandomState(1337)\n",
        "def val_set_mse(X, y, random_state):\n",
        "  split = ShuffleSplit(n_splits=1, train_size=0.5, random_state=random_state)\n",
        "  scores = cross_val_score(model, X, y, cv=split, scoring = 'neg_root_mean_squared_error') \n",
        "  #cv can be None (5 fold cross val), an int (Kfold), CV splitter, or Iterable yielding splits as array of indices\n",
        "  \n",
        "  return abs(np.mean(scores))\n",
        "\n",
        "\n",
        "display(val_set_mse(df[['x']], df.y,random_state))\n",
        "\n",
        "\n",
        "\n",
        "# more code\n",
        "#for trial in range(TRIALS):\n",
        "#    for order in range(1, MAX_ORDER+1):\n",
        "#      variable_to_assign = val_set_mse(df.X, df.y, random_state)\n",
        "#---------------------------------------------\n",
        "\n",
        "STEP_6_COMPLETE = True"
      ],
      "execution_count": 97,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "2.517091712906679"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KEgG-JYdf9tm"
      },
      "source": [
        "##### STEP 7: dataframe of val set rmse\n",
        "\n",
        "In this step, you'll generate a DataFrame of RMSE values for 10 trials of 8 models using the Validation Set approach. Each model will represent an increasing order polynomial feature set. For example, the first value in the DataFrame for Trial 1 will be the the RMSE for a 1st order $(x^1)$ model, whereas the eighth value will be the MSE for an 8th order $(x^1, x^2, ... , x^8)$ model. The resulting DataFrame might look something like this:\n",
        "\n",
        "```\n",
        "    Trial 1   Trial 2   Trial 3   Trial 4   Trial 5   Trial 6   Trial 7   Trial 8   Trial 9  Trial 10 \n",
        "1  1.195520  1.307997  1.390264  1.299595  1.320461  1.170825  1.256463  1.321078  1.247050  1.212689   \n",
        "2  0.635550  0.621675  0.668410  0.627653  0.625856  0.639784  0.594125  0.638596  0.563780  0.633923   \n",
        "3  0.561838  0.582483  0.604784  0.639694  0.612064  0.593695  0.605464  0.569258  0.605322  0.665788   \n",
        "4  0.650670  0.655353  0.671473  0.638411  0.614336  0.609196  0.658455  0.709729  0.661375  0.595443   \n",
        "5  0.655897  0.670315  0.652939  0.663934  0.699677  0.587052  0.647100  0.669904  0.597044  0.573686   \n",
        "6  0.605551  0.559774  0.656311  0.617817  0.666769  0.577362  0.643648  0.622396  0.681107  0.689736   \n",
        "7  0.601836  0.633743  0.634507  0.635380  0.636882  0.633724  0.666757  0.676464  0.674024  0.639023   \n",
        "8  0.607631  0.639835  0.676559  0.668600  0.660138  0.654388  0.636267  0.659123  0.654003  0.642247   \n",
        "```\n",
        "\n",
        "Hints:\n",
        "\n",
        "- Adding each trial as a column is not necessarily intuitive. For many, it's more straight-forward to think of trials as rows with the each column representing the order of polynomial. The reason we use Trials as the columns is that the `matplotlib` package will plot lines using columns as the series values. It involves some Python gymnastics to plot rows instead of columns--better to handle it now.\n",
        "- You will use your `poly_df` function to generate polynomial feature data\n",
        "- The most straight-forward approach involves iterating over 10 trials and 8 orders of polynomials to assign the MSE values to an numpy array. Then, after you've filled your array, you'll create a DataFrame specifying indices (row labels 1-8) and column headers (Trial numbers)\n",
        "- Assuming you implemented RandomState in `val_set_mse`, here you'll initialize a RandomState object at the beginning of the cell and pass in to `val_set_mse`. In this way, every time you run this cell, you'll get the same sequence of random train/validation set partitions.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GONYy_mkkyI1"
      },
      "source": [
        "#STEP 7\n",
        "\n",
        "#STUDENT CODE - create DataFrame of Trial and Order data\n",
        "#---------------------------------------------\n",
        "\n",
        "#---------------------------------------------\n",
        "\n",
        "STEP_7_COMPLETE = False"
      ],
      "execution_count": 81,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2Hk42skZkz6O"
      },
      "source": [
        "##### STEP 8: plot val set cv\n",
        "\n",
        "In this step, create a spaghetti plot of each of the 10 trials. Be sure to label your axes.\n",
        "\n",
        "Example of resulting plot:\n",
        "\n",
        "![val set mse spaghetti plot](https://raw.githubusercontent.com/afit-csce623-master/template-hw3/main/images/val_set_spaghetti.png)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4Ud1UJSokzCz"
      },
      "source": [
        "#STEP 8\n",
        "\n",
        "#STUDENT CODE - plot validation set spaghetti charts\n",
        "#---------------------------------------------\n",
        "\n",
        "#---------------------------------------------\n",
        "\n",
        "STEP_8_COMPLETE = False"
      ],
      "execution_count": 82,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CMSW4czeIXnX"
      },
      "source": [
        "#### Leave-One-Out Cross-Validation\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lFIpRurDxrvK"
      },
      "source": [
        "##### STEP 9: loocv rmse\n",
        "\n",
        "In this step, you'll create loocv_mse(X, y, random_state) which returns the average root mean squared error of models fit to training sets and evaluated on the validation sets as defined by the Leave-One-Out Cross Validation approach.\n",
        "\n",
        "- X is a DataFrame of feature inputs\n",
        "- y is a Series of targets\n",
        "- return a scalar value representing the root mean squared error\n",
        "\n",
        "Hints:\n",
        "- See hints in STEP 6 for guidance here\n",
        "- One caveat to consider... what is the type/shape of the value returned by the `cross_val_score` method in STEP 6? What is it here? Another way to think about this question is how many models are being evaluated in the Validation Set approach (STEP 6)? How many models are being evaluted in LOOVC? If your function is expected to return a single RMSE, what will you do differently, here?\n",
        "- Your code will likely look nearly identical to that in STEP 6. Don't worry about avoiding repeatition... in practice, you will rarely implement more than one method of cross-validation in your research. Therefore, it's reasonable to generate the full workflow here as a possible source for your research later  (apart from reuse of constants from the SETUP B step above)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xP_Ecu00OXQK"
      },
      "source": [
        "#STEP 9\n",
        "\n",
        "#STUDENT CODE - create loocv_mse(X, y, random_state)\n",
        "#---------------------------------------------\n",
        "\n",
        "#---------------------------------------------\n",
        "\n",
        "STEP_9_COMPLETE = False"
      ],
      "execution_count": 83,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KZonhX4oxuTH"
      },
      "source": [
        "##### STEP 10: dataframe of loocv rmse\n",
        "\n",
        "In this step, you'll generate a DataFrame of RMSE values for 1 trial of 8 models using the Leave One Out Cross-Validation approach. As in STEP 7, each model will represent an increasing order polynomial feature set. For example, the first value in the DataFrame for Trial 1 will be the the RMSE for a 1st order $(x^1)$ model, whereas the eighth value will be the MSE for an 8th order $(x^1, x^2, ... , x^8)$ model.\n",
        "\n",
        "Hints:\n",
        "- Unlike STEP 7, you'll have only one column of data representing a single trial of 8 models of polynomials"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PX4OBFELpgHb"
      },
      "source": [
        "#STEP 10\n",
        "\n",
        "#STUDENT CODE - create DataFrame of LOOCV Order data\n",
        "#---------------------------------------------\n",
        "\n",
        "#---------------------------------------------\n",
        "\n",
        "STEP_10_COMPLETE = True"
      ],
      "execution_count": 84,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N2ieXkh7xxSh"
      },
      "source": [
        "##### STEP 11: plot loocv\n",
        "\n",
        "In this step, create a spaghetti plot of LOOVC for each order polynomial model. Be sure to label your axes.\n",
        "\n",
        "- Your plot might look something like this (specific values will vary):\n",
        "\n",
        "![loocv spaghetti plot](https://raw.githubusercontent.com/afit-csce623-master/template-hw3/main/images/loocv_spaghetti.png)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2TthIazms3rL"
      },
      "source": [
        "#STEP 11\n",
        "\n",
        "#STUDENT CODE - plot loocv spaghetti chart\n",
        "#---------------------------------------------\n",
        "\n",
        "#---------------------------------------------\n",
        "\n",
        "STEP_11_COMPLETE = False"
      ],
      "execution_count": 85,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "emh-0CO0Iqm5"
      },
      "source": [
        "#### k-Fold Cross Validation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VPV2ZssE7ZAs"
      },
      "source": [
        "##### STEP 12: kfold rmse\n",
        "\n",
        "In this step, you'll create kfold_mse(X, y, k, random_state) which returns the average root mean squared error of models fit to training sets and evaluated on the validation sets as defined by the k-fold cross-validation approach.\n",
        "\n",
        "- `X` is a DataFrame of feature inputs\n",
        "- `y` is a Series of targets\n",
        "- `k` is the number of folds \n",
        "- return a scalar value representing the root mean squared error\n",
        "\n",
        "Hints:\n",
        "- See hints in STEP 6 STEP 9 for guidance here\n",
        "- Though `cross_val_score` provides a mechanism to pass an integer via the `cv` argument to implement k-fold CV without a cross-validation iterator, this method does not randomize or shuffle the train and validation sets. As you the next step will require that you run multiple trials, do not use the short provided in `cross_val_score` to use k-fold CV. Instead, select the appropriate cross-validation generator with the appropriate `shuffle` and `random_state` values."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AlaH-SV4s2SU"
      },
      "source": [
        "#STEP 12\n",
        "\n",
        "#STUDENT CODE - create kfold_mse(X, y, k, random_state)\n",
        "#---------------------------------------------\n",
        "\n",
        "#---------------------------------------------\n",
        "\n",
        "STEP_12_COMPLETE = False"
      ],
      "execution_count": 86,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F0uDpcHF7i-_"
      },
      "source": [
        "##### STEP 13: dataframe of kfold rmse\n",
        "\n",
        "In this step, you'll generate a DataFrame of RMSE values for 10 trials of 8 models using the 10-fold cross-validation approach."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TGwJgcKIxHXK"
      },
      "source": [
        "#STEP 13\n",
        "\n",
        "#STUDENT CODE - create DataFrame of LOOCV Order data\n",
        "#---------------------------------------------\n",
        "\n",
        "#---------------------------------------------\n",
        "\n",
        "STEP_13_COMPLETE = True"
      ],
      "execution_count": 87,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cjMRS9oJ7o_Y"
      },
      "source": [
        "##### STEP 14: plot kfold rmse\n",
        "\n",
        "In this step, create a spaghetti plot of the k-fold trials. Be sure to label your axes.\n",
        "\n",
        "- Your plot might look something like this (specific values will vary):\n",
        "\n",
        "![kfold spaghetti plot](https://raw.githubusercontent.com/afit-csce623-master/template-hw3/main/images/kfold_spaghetti.png)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZF7lkpxrxBxf"
      },
      "source": [
        "#STEP 14\n",
        "\n",
        "#STUDENT CODE - plot k-fold spaghetti charts\n",
        "#---------------------------------------------\n",
        "\n",
        "#---------------------------------------------\n",
        "\n",
        "STEP_14_COMPLETE = False"
      ],
      "execution_count": 88,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rcadU5rtBQty"
      },
      "source": [
        "#### Discussion"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5eeVWo-DBTzA"
      },
      "source": [
        "##### STEP 15: analysis\n",
        "\n",
        "Review the spaghetti charts created in STEPS 8, 11, and 14, then answer the following questions.\n",
        "\n",
        "- For both the Validation Set and for k-fold approaches we conducted 10 trials, and there was variation between them. What would have occurred had we conducted 10 trials of LOOCV?\n",
        "\n",
        "  <font color=green class=\"student_answer\">Student Discussion</font>\n",
        "\n",
        "\n",
        "- Which cross-validation approach has the greatest variation from one trial to the next? Why?\n",
        "\n",
        "  <font color=green class=\"student_answer\">Student Discussion</font>\n",
        "\n",
        "- Which cross-validation approach has the least variation from one trial to the next? Why?\n",
        "\n",
        "  <font color=green class=\"student_answer\">Student Discussion</font>\n",
        "\n",
        "- Suppose you had observations whose targets (y-values) range from $[0-10]$. When you conduct cross-validation, you note that the model of polynomial order $p$ yields an RMSE of 0.0800, but the model of polynomial order $p+4$ yields an RMSE of 0.0792. In terms of $p$, which model will you use and why?\n",
        "\n",
        "  <font color=green class=\"student_answer\">Student Discussion</font>\n",
        "\n",
        "- Which CV approach do you think will be most appropriate for your machine learning research? Why?\n",
        "\n",
        "  <font color=green class=\"student_answer\">Student Discussion</font>\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wlFt5LcDiR3s"
      },
      "source": [
        "STEP_15_COMPLETE = False"
      ],
      "execution_count": 89,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4vITNJhSEbQg"
      },
      "source": [
        "##### STEP 16: model selection\n",
        "\n",
        "Based on your analysis of cross-validation, which order polynomial model will you choose? Why?\n",
        "\n",
        "  <font color=green class=\"student_answer\">Student Discussion</font>\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G1MKk23PiUdk"
      },
      "source": [
        "STEP_16_COMPLETE = False"
      ],
      "execution_count": 90,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rcYHRbbiE7bm"
      },
      "source": [
        "#### Model Creation & Evaluation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TppVvahYE-i5"
      },
      "source": [
        "##### STEP 17: Model Creation\n",
        "\n",
        "In this step, you will generate a model of the polynomial order you identified in STEP 16 (using your `poly_df` function). Then, you will fit that model to your data.\n",
        "\n",
        "Finally, you'll plot your model, along with the original data and your initial guess. Be sure to label your plot. Here is an example of a possible result:\n",
        "\n",
        "![fit model plot](https://raw.githubusercontent.com/afit-csce623-master/template-hw3/main/images/plot_fit_overlay2.png)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ivtDGgQlFBop"
      },
      "source": [
        "#STEP 17\n",
        "\n",
        "#STUDENT CODE - fit model, plot initial guess and best fit line\n",
        "#---------------------------------------------\n",
        "\n",
        "#---------------------------------------------\n",
        "\n",
        "STEP_17_COMPLETE = False"
      ],
      "execution_count": 91,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9gyQOP6uPhqO"
      },
      "source": [
        "##### STEP 18: Model Evaluation\n",
        "\n",
        "In this step, you will generate test data and evaluate the performance of your fitted model on that test data.\n",
        "\n",
        "Hints:\n",
        "- To generate test data, you will use the `generate_data()` function. It is critical you reuse the seed value that you used in STEP 2. Using a different seed value will result in you creating test data generated from a different data signal, and your model will inevitably perform disastrously. Also, you will need to set the optional argument `test_data` to `True`:\n",
        "\n",
        "  `df_test = generate_data(seed, test_data=True)`\n",
        "\n",
        "  You should use the actual value of `seed` unless you are ABSOLUTELY sure that you have not modified it somewhere in the notebook\n",
        "\n",
        "- After you have generated the data, be sure that you engineer a feature set of the appropriate polynomial order.\n",
        "\n",
        "- Page 80 of _HOML_ provides an example of how you can calculate the RMSE of your model on test data. Note that the text calculates the square root of the mean squared error. If you take a look at the [mean_squared_error](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.mean_squared_error.html) function, you'll see that you can set an argument to return the RMSE, without a need to take a square root of the result.\n",
        "\n",
        "- Note that the instructor solution for this step involves approximately 5 steps. If you are using significantly more than that, you may not be effectively using the functions you've created or the scikit-learn tools."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vMS5haVjWHMF"
      },
      "source": [
        "#STEP 18\n",
        "\n",
        "#STUDENT CODE - generate test data, calculate rmse on test data\n",
        "#---------------------------------------------\n",
        "\n",
        "#---------------------------------------------\n",
        "\n",
        "STEP_18_COMPLETE = False"
      ],
      "execution_count": 92,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lXQiXKD8jjsi"
      },
      "source": [
        "#### STEP 19: final model discussion\n",
        "\n",
        "Answer the following questions\n",
        "\n",
        "- What is your model's performance on test data?\n",
        "\n",
        "  <font color=green class=\"student_answer\">Student Discussion</font>\n",
        "\n",
        "\n",
        "- How does this compare to the cross-validation error that you used to determine the polynomial order for your model?\n",
        "\n",
        "  <font color=green class=\"student_answer\">Student Discussion</font>\n",
        "\n",
        "- What accounts for the difference between the cross-validation error and the error on the test data?\n",
        "\n",
        "  <font color=green class=\"student_answer\">Student Discussion</font>\n",
        "\n",
        "- What is the most appropriate metric to use when advertising the performance of your model?\n",
        "\n",
        "  <font color=green class=\"student_answer\">Student Discussion</font>\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5o2lfeA6kVYn"
      },
      "source": [
        "STEP_19_COMPLETE = False"
      ],
      "execution_count": 93,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gCsY--TI02Jw"
      },
      "source": [
        "# Enter the number of hours you spend on this homework assignment as a floating point value\n",
        "\n",
        "hours_spent = 0.0\n",
        "\n",
        "STEP_20_COMPLETE = False"
      ],
      "execution_count": 94,
      "outputs": []
    }
  ]
}